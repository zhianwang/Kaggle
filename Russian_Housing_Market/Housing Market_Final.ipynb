{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sberbank Russian Housing Market\n",
    "#### Team Member: Zhian Wang; Ying Zhang\n",
    "#### Data Source: https://www.kaggle.com/c/sberbank-russian-housing-market/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import model_selection, preprocessing\n",
    "import xgboost as xgb\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "wd = \"/Users/zwang/GWU/Kaggle/Housing_Mkt/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:7.96311e+06\ttest-rmse:7.96868e+06\n",
      "[25]\ttrain-rmse:3.39599e+06\ttest-rmse:3.58856e+06\n",
      "[50]\ttrain-rmse:2.44957e+06\ttest-rmse:2.81627e+06\n",
      "[75]\ttrain-rmse:2.22139e+06\ttest-rmse:2.68314e+06\n",
      "[100]\ttrain-rmse:2.12427e+06\ttest-rmse:2.63849e+06\n",
      "[125]\ttrain-rmse:2.06274e+06\ttest-rmse:2.61565e+06\n",
      "[150]\ttrain-rmse:2.01144e+06\ttest-rmse:2.60251e+06\n",
      "[175]\ttrain-rmse:1.96638e+06\ttest-rmse:2.59128e+06\n",
      "[200]\ttrain-rmse:1.9241e+06\ttest-rmse:2.58258e+06\n",
      "[225]\ttrain-rmse:1.88682e+06\ttest-rmse:2.576e+06\n",
      "[250]\ttrain-rmse:1.85685e+06\ttest-rmse:2.57113e+06\n",
      "[275]\ttrain-rmse:1.82648e+06\ttest-rmse:2.5675e+06\n",
      "[300]\ttrain-rmse:1.79886e+06\ttest-rmse:2.56462e+06\n",
      "[325]\ttrain-rmse:1.77261e+06\ttest-rmse:2.56276e+06\n",
      "[350]\ttrain-rmse:1.74566e+06\ttest-rmse:2.56139e+06\n",
      "[375]\ttrain-rmse:1.72373e+06\ttest-rmse:2.56074e+06\n",
      "[400]\ttrain-rmse:1.70019e+06\ttest-rmse:2.56027e+06\n",
      "best num_boost_rounds =  382\n"
     ]
    }
   ],
   "source": [
    "#read csv files\n",
    "train = pd.read_csv(wd+'train.csv')\n",
    "test = pd.read_csv(wd+'test.csv')\n",
    "id_test = test.id\n",
    "id_train = train.id\n",
    "\n",
    "mult = .969\n",
    "\n",
    "y_train = train[\"price_doc\"] * mult + 10\n",
    "x_train = train.drop([\"id\", \"timestamp\", \"price_doc\"], axis=1)\n",
    "x_test = test.drop([\"id\", \"timestamp\"], axis=1)\n",
    "\n",
    "#Encode Categorical Variables\n",
    "for c in x_train.columns:\n",
    "    if x_train[c].dtype == 'object':\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(x_train[c].values))\n",
    "        x_train[c] = lbl.transform(list(x_train[c].values))\n",
    "\n",
    "for c in x_test.columns:\n",
    "    if x_test[c].dtype == 'object':\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(x_test[c].values))\n",
    "        x_test[c] = lbl.transform(list(x_test[c].values))\n",
    "\n",
    "# Run XGB Model\n",
    "xgb_params = {\n",
    "    'eta': 0.05,\n",
    "    'max_depth': 5,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'rmse',\n",
    "    'silent': 1\n",
    "}\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train, y_train)\n",
    "dtest = xgb.DMatrix(x_test)\n",
    "\n",
    "cv_output = xgb.cv(xgb_params, dtrain, num_boost_round=1000, early_stopping_rounds=20, verbose_eval=25, show_stdv=False)\n",
    "print('best num_boost_rounds = ', len(cv_output))\n",
    "num_boost_rounds = len(cv_output) # 382\n",
    "\n",
    "model01 = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round= num_boost_rounds)\n",
    "\n",
    "#y_predict = model01.predict(dtest)\n",
    "#output01 = pd.DataFrame({'id': id_test, 'price_doc': y_predict01})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ytest_pred01 = model01.predict(dtrain)\n",
    "\n",
    "df_train01 = pd.DataFrame({'id': id_train, 'price_pred01': ytrain_pred01})\n",
    "\n",
    "df_train01.to_csv(wd+\"/stacking/model01_train.csv\", index=False)\n",
    "\n",
    "ytest_pred01 = model01.predict(dtest)\n",
    "\n",
    "df_test01 = pd.DataFrame({'id': id_test, 'price_pred01': ytest_pred01})\n",
    "\n",
    "df_test01.to_csv(wd+\"/stacking/model01_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price_pred01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5287640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5327946.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5523237.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10826237.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>13112374.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  price_pred01\n",
       "0   1     5287640.0\n",
       "1   2     5327946.5\n",
       "2   3     5523237.5\n",
       "3   4    10826237.0\n",
       "4   5    13112374.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train01.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price changed done\n",
      "[0]\ttrain-rmse:8.36817e+06\ttest-rmse:8.37654e+06\n",
      "[20]\ttrain-rmse:3.87109e+06\ttest-rmse:4.06809e+06\n",
      "[40]\ttrain-rmse:2.55887e+06\ttest-rmse:2.95699e+06\n",
      "[60]\ttrain-rmse:2.19696e+06\ttest-rmse:2.7154e+06\n",
      "[80]\ttrain-rmse:2.0698e+06\ttest-rmse:2.65022e+06\n",
      "[100]\ttrain-rmse:1.99866e+06\ttest-rmse:2.61855e+06\n",
      "[120]\ttrain-rmse:1.93928e+06\ttest-rmse:2.60026e+06\n",
      "[140]\ttrain-rmse:1.88787e+06\ttest-rmse:2.58727e+06\n",
      "[160]\ttrain-rmse:1.84485e+06\ttest-rmse:2.57806e+06\n",
      "[180]\ttrain-rmse:1.80239e+06\ttest-rmse:2.57017e+06\n",
      "[200]\ttrain-rmse:1.76422e+06\ttest-rmse:2.56489e+06\n",
      "[220]\ttrain-rmse:1.72663e+06\ttest-rmse:2.56031e+06\n",
      "[240]\ttrain-rmse:1.68808e+06\ttest-rmse:2.55718e+06\n",
      "[260]\ttrain-rmse:1.65692e+06\ttest-rmse:2.55373e+06\n",
      "[280]\ttrain-rmse:1.62677e+06\ttest-rmse:2.55215e+06\n",
      "[300]\ttrain-rmse:1.60138e+06\ttest-rmse:2.55103e+06\n",
      "[320]\ttrain-rmse:1.57315e+06\ttest-rmse:2.55012e+06\n",
      "[340]\ttrain-rmse:1.54578e+06\ttest-rmse:2.54815e+06\n",
      "best num_boost_rounds =  341\n"
     ]
    }
   ],
   "source": [
    "#read  csv files\n",
    "train = pd.read_csv(wd+'train.csv', parse_dates=['timestamp'])\n",
    "test = pd.read_csv(wd+'test.csv', parse_dates=['timestamp'])\n",
    "id_test = test.id\n",
    "\n",
    "#preparing data\n",
    "bad_index = train[train.life_sq > train.full_sq].index\n",
    "train.loc[bad_index, \"life_sq\"] = np.NaN\n",
    "equal_index = [601,1896,2791]\n",
    "test.loc[equal_index, \"life_sq\"] = test.loc[equal_index, \"full_sq\"]\n",
    "bad_index = test[test.life_sq > test.full_sq].index\n",
    "test.loc[bad_index, \"life_sq\"] = np.NaN\n",
    "bad_index = train[train.life_sq < 5].index\n",
    "train.loc[bad_index, \"life_sq\"] = np.NaN\n",
    "bad_index = test[test.life_sq < 5].index\n",
    "test.loc[bad_index, \"life_sq\"] = np.NaN\n",
    "bad_index = train[train.full_sq < 5].index\n",
    "train.loc[bad_index, \"full_sq\"] = np.NaN\n",
    "bad_index = test[test.full_sq < 5].index\n",
    "test.loc[bad_index, \"full_sq\"] = np.NaN\n",
    "kitch_is_build_year = [13117]\n",
    "train.loc[kitch_is_build_year, \"build_year\"] = train.loc[kitch_is_build_year, \"kitch_sq\"]\n",
    "bad_index = train[train.kitch_sq >= train.life_sq].index\n",
    "train.loc[bad_index, \"kitch_sq\"] = np.NaN\n",
    "bad_index = test[test.kitch_sq >= test.life_sq].index\n",
    "test.loc[bad_index, \"kitch_sq\"] = np.NaN\n",
    "bad_index = train[(train.kitch_sq == 0).values + (train.kitch_sq == 1).values].index\n",
    "train.loc[bad_index, \"kitch_sq\"] = np.NaN\n",
    "bad_index = test[(test.kitch_sq == 0).values + (test.kitch_sq == 1).values].index\n",
    "test.loc[bad_index, \"kitch_sq\"] = np.NaN\n",
    "bad_index = train[(train.full_sq > 210) & (train.life_sq / train.full_sq < 0.3)].index\n",
    "train.loc[bad_index, \"full_sq\"] = np.NaN\n",
    "bad_index = test[(test.full_sq > 150) & (test.life_sq / test.full_sq < 0.3)].index\n",
    "test.loc[bad_index, \"full_sq\"] = np.NaN\n",
    "bad_index = train[train.life_sq > 300].index\n",
    "train.loc[bad_index, [\"life_sq\", \"full_sq\"]] = np.NaN\n",
    "bad_index = test[test.life_sq > 200].index\n",
    "test.loc[bad_index, [\"life_sq\", \"full_sq\"]] = np.NaN\n",
    "train.product_type.value_counts(normalize= True)\n",
    "test.product_type.value_counts(normalize= True)\n",
    "bad_index = train[train.build_year < 1500].index\n",
    "train.loc[bad_index, \"build_year\"] = np.NaN\n",
    "bad_index = test[test.build_year < 1500].index\n",
    "test.loc[bad_index, \"build_year\"] = np.NaN\n",
    "bad_index = train[train.num_room == 0].index\n",
    "train.loc[bad_index, \"num_room\"] = np.NaN\n",
    "bad_index = test[test.num_room == 0].index\n",
    "test.loc[bad_index, \"num_room\"] = np.NaN\n",
    "bad_index = [10076, 11621, 17764, 19390, 24007, 26713, 29172]\n",
    "train.loc[bad_index, \"num_room\"] = np.NaN\n",
    "bad_index = [3174, 7313]\n",
    "test.loc[bad_index, \"num_room\"] = np.NaN\n",
    "bad_index = train[(train.floor == 0).values * (train.max_floor == 0).values].index\n",
    "train.loc[bad_index, [\"max_floor\", \"floor\"]] = np.NaN\n",
    "bad_index = train[train.floor == 0].index\n",
    "train.loc[bad_index, \"floor\"] = np.NaN\n",
    "bad_index = train[train.max_floor == 0].index\n",
    "train.loc[bad_index, \"max_floor\"] = np.NaN\n",
    "bad_index = test[test.max_floor == 0].index\n",
    "test.loc[bad_index, \"max_floor\"] = np.NaN\n",
    "bad_index = train[train.floor > train.max_floor].index\n",
    "train.loc[bad_index, \"max_floor\"] = np.NaN\n",
    "bad_index = test[test.floor > test.max_floor].index\n",
    "test.loc[bad_index, \"max_floor\"] = np.NaN\n",
    "train.floor.describe(percentiles= [0.9999])\n",
    "bad_index = [23584]\n",
    "train.loc[bad_index, \"floor\"] = np.NaN\n",
    "train.material.value_counts()\n",
    "test.material.value_counts()\n",
    "train.state.value_counts()\n",
    "bad_index = train[train.state == 33].index\n",
    "train.loc[bad_index, \"state\"] = np.NaN\n",
    "test.state.value_counts()\n",
    "\n",
    "# removing extreme price per sqm\n",
    "train.loc[train.full_sq == 0, 'full_sq'] = 50\n",
    "train = train[train.price_doc/train.full_sq <= 600000]\n",
    "train = train[train.price_doc/train.full_sq >= 10000]\n",
    "\n",
    "# Add month-year\n",
    "month_year = (train.timestamp.dt.month + train.timestamp.dt.year * 100)\n",
    "month_year_cnt_map = month_year.value_counts().to_dict()\n",
    "train['month_year_cnt'] = month_year.map(month_year_cnt_map)\n",
    "\n",
    "month_year = (test.timestamp.dt.month + test.timestamp.dt.year * 100)\n",
    "month_year_cnt_map = month_year.value_counts().to_dict()\n",
    "test['month_year_cnt'] = month_year.map(month_year_cnt_map)\n",
    "\n",
    "# Add week-year count\n",
    "week_year = (train.timestamp.dt.weekofyear + train.timestamp.dt.year * 100)\n",
    "week_year_cnt_map = week_year.value_counts().to_dict()\n",
    "train['week_year_cnt'] = week_year.map(week_year_cnt_map)\n",
    "\n",
    "week_year = (test.timestamp.dt.weekofyear + test.timestamp.dt.year * 100)\n",
    "week_year_cnt_map = week_year.value_counts().to_dict()\n",
    "test['week_year_cnt'] = week_year.map(week_year_cnt_map)\n",
    "\n",
    "# Add month and day-of-week\n",
    "train['month'] = train.timestamp.dt.month\n",
    "train['dow'] = train.timestamp.dt.dayofweek\n",
    "\n",
    "test['month'] = test.timestamp.dt.month\n",
    "test['dow'] = test.timestamp.dt.dayofweek\n",
    "\n",
    "# feature engineering - adding new fratures\n",
    "train['rel_floor'] = train['floor'] / train['max_floor'].astype(float)\n",
    "train['rel_kitch_sq'] = train['kitch_sq'] / train['full_sq'].astype(float)\n",
    "\n",
    "test['rel_floor'] = test['floor'] / test['max_floor'].astype(float)\n",
    "test['rel_kitch_sq'] = test['kitch_sq'] / test['full_sq'].astype(float)\n",
    "\n",
    "train.apartment_name=train.sub_area + train['metro_km_avto'].astype(str)\n",
    "test.apartment_name=test.sub_area + train['metro_km_avto'].astype(str)\n",
    "\n",
    "train['room_size'] = train['life_sq'] / train['num_room'].astype(float)\n",
    "test['room_size'] = test['life_sq'] / test['num_room'].astype(float)\n",
    "\n",
    "train['year_old'] = 2018 - train['build_year']\n",
    "test['year_old'] = 2018 - train['build_year']\n",
    "\n",
    "\n",
    "rate_2016_q2 = 1\n",
    "rate_2016_q1 = rate_2016_q2 / .99903\n",
    "rate_2015_q4 = rate_2016_q1 / .9831\n",
    "rate_2015_q3 = rate_2015_q4 / .9834\n",
    "rate_2015_q2 = rate_2015_q3 / .9815\n",
    "rate_2015_q1 = rate_2015_q2 / .9932\n",
    "rate_2014_q4 = rate_2015_q1 / 1.0112\n",
    "rate_2014_q3 = rate_2014_q4 / 1.0169\n",
    "rate_2014_q2 = rate_2014_q3 / 1.0086\n",
    "rate_2014_q1 = rate_2014_q2 / 1.0126\n",
    "rate_2013_q4 = rate_2014_q1 / 0.9902\n",
    "rate_2013_q3 = rate_2013_q4 / 1.0041\n",
    "rate_2013_q2 = rate_2013_q3 / 1.0044\n",
    "rate_2013_q1 = rate_2013_q2 / 1.0104\n",
    "rate_2012_q4 = rate_2013_q1 / 0.9832\n",
    "rate_2012_q3 = rate_2012_q4 / 1.0277\n",
    "rate_2012_q2 = rate_2012_q3 / 1.0279\n",
    "rate_2012_q1 = rate_2012_q2 / 1.0279\n",
    "rate_2011_q4 = rate_2012_q1 / 1.076\n",
    "rate_2011_q3 = rate_2011_q4 / 1.0236\n",
    "rate_2011_q2 = rate_2011_q3 / 1\n",
    "rate_2011_q1 = rate_2011_q2 / 1.011\n",
    "\n",
    "# test data\n",
    "test['average_q_price'] = 1\n",
    "\n",
    "test_2016_q2_index = test.loc[test['timestamp'].dt.year == 2016].loc[test['timestamp'].dt.month >= 4].loc[test['timestamp'].dt.month <= 7].index\n",
    "test.loc[test_2016_q2_index, 'average_q_price'] = rate_2016_q2\n",
    "\n",
    "test_2016_q1_index = test.loc[test['timestamp'].dt.year == 2016].loc[test['timestamp'].dt.month >= 1].loc[test['timestamp'].dt.month < 4].index\n",
    "test.loc[test_2016_q1_index, 'average_q_price'] = rate_2016_q1\n",
    "\n",
    "test_2015_q4_index = test.loc[test['timestamp'].dt.year == 2015].loc[test['timestamp'].dt.month >= 10].loc[test['timestamp'].dt.month < 12].index\n",
    "test.loc[test_2015_q4_index, 'average_q_price'] = rate_2015_q4\n",
    "\n",
    "test_2015_q3_index = test.loc[test['timestamp'].dt.year == 2015].loc[test['timestamp'].dt.month >= 7].loc[test['timestamp'].dt.month < 10].index\n",
    "test.loc[test_2015_q3_index, 'average_q_price'] = rate_2015_q3\n",
    "\n",
    "test_2015_q2_index = test.loc[test['timestamp'].dt.year == 2015].loc[test['timestamp'].dt.month >= 4].loc[test['timestamp'].dt.month < 7].index\n",
    "test.loc[test_2015_q2_index, 'average_q_price'] = rate_2015_q2\n",
    "\n",
    "test_2015_q1_index = test.loc[test['timestamp'].dt.year == 2015].loc[test['timestamp'].dt.month >= 4].loc[test['timestamp'].dt.month < 7].index\n",
    "test.loc[test_2015_q1_index, 'average_q_price'] = rate_2015_q1\n",
    "\n",
    "\n",
    "# train 2015\n",
    "train['average_q_price'] = 1\n",
    "\n",
    "train_2015_q4_index = train.loc[train['timestamp'].dt.year == 2015].loc[train['timestamp'].dt.month >= 10].loc[train['timestamp'].dt.month <= 12].index\n",
    "train.loc[train_2015_q4_index, 'average_q_price'] = rate_2015_q4\n",
    "\n",
    "train_2015_q3_index = train.loc[train['timestamp'].dt.year == 2015].loc[train['timestamp'].dt.month >= 7].loc[train['timestamp'].dt.month < 10].index\n",
    "train.loc[train_2015_q3_index, 'average_q_price'] = rate_2015_q3\n",
    "\n",
    "train_2015_q2_index = train.loc[train['timestamp'].dt.year == 2015].loc[train['timestamp'].dt.month >= 4].loc[train['timestamp'].dt.month < 7].index\n",
    "train.loc[train_2015_q2_index, 'average_q_price'] = rate_2015_q2\n",
    "\n",
    "train_2015_q1_index = train.loc[train['timestamp'].dt.year == 2015].loc[train['timestamp'].dt.month >= 1].loc[train['timestamp'].dt.month < 4].index\n",
    "train.loc[train_2015_q1_index, 'average_q_price'] = rate_2015_q1\n",
    "\n",
    "\n",
    "# train 2014\n",
    "train_2014_q4_index = train.loc[train['timestamp'].dt.year == 2014].loc[train['timestamp'].dt.month >= 10].loc[train['timestamp'].dt.month <= 12].index\n",
    "train.loc[train_2014_q4_index, 'average_q_price'] = rate_2014_q4\n",
    "\n",
    "train_2014_q3_index = train.loc[train['timestamp'].dt.year == 2014].loc[train['timestamp'].dt.month >= 7].loc[train['timestamp'].dt.month < 10].index\n",
    "train.loc[train_2014_q3_index, 'average_q_price'] = rate_2014_q3\n",
    "\n",
    "train_2014_q2_index = train.loc[train['timestamp'].dt.year == 2014].loc[train['timestamp'].dt.month >= 4].loc[train['timestamp'].dt.month < 7].index\n",
    "train.loc[train_2014_q2_index, 'average_q_price'] = rate_2014_q2\n",
    "\n",
    "train_2014_q1_index = train.loc[train['timestamp'].dt.year == 2014].loc[train['timestamp'].dt.month >= 1].loc[train['timestamp'].dt.month < 4].index\n",
    "train.loc[train_2014_q1_index, 'average_q_price'] = rate_2014_q1\n",
    "\n",
    "\n",
    "# train 2013\n",
    "train_2013_q4_index = train.loc[train['timestamp'].dt.year == 2013].loc[train['timestamp'].dt.month >= 10].loc[train['timestamp'].dt.month <= 12].index\n",
    "train.loc[train_2013_q4_index, 'average_q_price'] = rate_2013_q4\n",
    "\n",
    "train_2013_q3_index = train.loc[train['timestamp'].dt.year == 2013].loc[train['timestamp'].dt.month >= 7].loc[train['timestamp'].dt.month < 10].index\n",
    "train.loc[train_2013_q3_index, 'average_q_price'] = rate_2013_q3\n",
    "\n",
    "train_2013_q2_index = train.loc[train['timestamp'].dt.year == 2013].loc[train['timestamp'].dt.month >= 4].loc[train['timestamp'].dt.month < 7].index\n",
    "train.loc[train_2013_q2_index, 'average_q_price'] = rate_2013_q2\n",
    "\n",
    "train_2013_q1_index = train.loc[train['timestamp'].dt.year == 2013].loc[train['timestamp'].dt.month >= 1].loc[train['timestamp'].dt.month < 4].index\n",
    "train.loc[train_2013_q1_index, 'average_q_price'] = rate_2013_q1\n",
    "\n",
    "\n",
    "# train 2012\n",
    "train_2012_q4_index = train.loc[train['timestamp'].dt.year == 2012].loc[train['timestamp'].dt.month >= 10].loc[train['timestamp'].dt.month <= 12].index\n",
    "train.loc[train_2012_q4_index, 'average_q_price'] = rate_2012_q4\n",
    "\n",
    "train_2012_q3_index = train.loc[train['timestamp'].dt.year == 2012].loc[train['timestamp'].dt.month >= 7].loc[train['timestamp'].dt.month < 10].index\n",
    "train.loc[train_2012_q3_index, 'average_q_price'] = rate_2012_q3\n",
    "\n",
    "train_2012_q2_index = train.loc[train['timestamp'].dt.year == 2012].loc[train['timestamp'].dt.month >= 4].loc[train['timestamp'].dt.month < 7].index\n",
    "train.loc[train_2012_q2_index, 'average_q_price'] = rate_2012_q2\n",
    "\n",
    "train_2012_q1_index = train.loc[train['timestamp'].dt.year == 2012].loc[train['timestamp'].dt.month >= 1].loc[train['timestamp'].dt.month < 4].index\n",
    "train.loc[train_2012_q1_index, 'average_q_price'] = rate_2012_q1\n",
    "\n",
    "\n",
    "# train 2011\n",
    "train_2011_q4_index = train.loc[train['timestamp'].dt.year == 2011].loc[train['timestamp'].dt.month >= 10].loc[train['timestamp'].dt.month <= 12].index\n",
    "train.loc[train_2011_q4_index, 'average_q_price'] = rate_2011_q4\n",
    "\n",
    "train_2011_q3_index = train.loc[train['timestamp'].dt.year == 2011].loc[train['timestamp'].dt.month >= 7].loc[train['timestamp'].dt.month < 10].index\n",
    "train.loc[train_2011_q3_index, 'average_q_price'] = rate_2011_q3\n",
    "\n",
    "train_2011_q2_index = train.loc[train['timestamp'].dt.year == 2011].loc[train['timestamp'].dt.month >= 4].loc[train['timestamp'].dt.month < 7].index\n",
    "train.loc[train_2011_q2_index, 'average_q_price'] = rate_2011_q2\n",
    "\n",
    "train_2011_q1_index = train.loc[train['timestamp'].dt.year == 2011].loc[train['timestamp'].dt.month >= 1].loc[train['timestamp'].dt.month < 4].index\n",
    "train.loc[train_2011_q1_index, 'average_q_price'] = rate_2011_q1\n",
    "\n",
    "train['price_doc'] = train['price_doc'] * train['average_q_price']\n",
    "\n",
    "print('price changed done')\n",
    "\n",
    "y_train = train[\"price_doc\"]\n",
    "id_train = train[\"id\"]\n",
    "x_train = train.drop([\"id\", \"timestamp\", \"price_doc\", \"average_q_price\"], axis=1)\n",
    "x_test = test.drop([\"id\", \"timestamp\", \"average_q_price\"], axis=1)\n",
    "\n",
    "num_train = len(x_train)\n",
    "x_all = pd.concat([x_train, x_test])\n",
    "\n",
    "for c in x_all.columns:\n",
    "    if x_all[c].dtype == 'object':\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(x_all[c].values))\n",
    "        x_all[c] = lbl.transform(list(x_all[c].values))\n",
    "\n",
    "x_train = x_all[:num_train]\n",
    "x_test = x_all[num_train:]\n",
    "\n",
    "\n",
    "xgb_params = {\n",
    "    'eta': 0.05,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.6,\n",
    "    'colsample_bytree': 1,\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'rmse',\n",
    "    'silent': 1\n",
    "}\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train, y_train)\n",
    "dtest = xgb.DMatrix(x_test)\n",
    "\n",
    "cv_output = xgb.cv(xgb_params, dtrain, num_boost_round=1000, early_stopping_rounds=20,\n",
    "verbose_eval=20, show_stdv=False)\n",
    "print('best num_boost_rounds = ', len(cv_output))\n",
    "num_boost_rounds = len(cv_output) \n",
    "\n",
    "model02 = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round=num_boost_rounds)\n",
    "\n",
    "#y_predict = model2.predict(dtest)\n",
    "#gunja_output = pd.DataFrame({'id': id_test, 'price_doc': y_predict})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ytrain_pred02 = model02.predict(dtrain)\n",
    "\n",
    "df_train02 = pd.DataFrame({'id': id_train, 'price_pred02': ytrain_pred02})\n",
    "\n",
    "df_train02.to_csv(wd+\"/stacking/model02_train.csv\", index=False)\n",
    "\n",
    "ytest_pred02 = model02.predict(dtest)\n",
    "\n",
    "df_test02 = pd.DataFrame({'id': id_test, 'price_pred02': ytest_pred02})\n",
    "\n",
    "df_test02.to_csv(wd+\"/stacking/model02_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38132, 390)\n",
      "(38132, 394)\n",
      "(38132, 394)\n",
      "[0]\ttrain-rmse:7.95097e+06\ttest-rmse:7.95387e+06\n",
      "[25]\ttrain-rmse:3.37924e+06\ttest-rmse:3.56281e+06\n",
      "[50]\ttrain-rmse:2.44345e+06\ttest-rmse:2.80129e+06\n",
      "[75]\ttrain-rmse:2.21997e+06\ttest-rmse:2.67461e+06\n",
      "[100]\ttrain-rmse:2.11538e+06\ttest-rmse:2.62903e+06\n",
      "[125]\ttrain-rmse:2.04485e+06\ttest-rmse:2.60543e+06\n",
      "[150]\ttrain-rmse:1.99219e+06\ttest-rmse:2.5905e+06\n",
      "[175]\ttrain-rmse:1.94894e+06\ttest-rmse:2.57984e+06\n",
      "[200]\ttrain-rmse:1.90718e+06\ttest-rmse:2.56996e+06\n",
      "[225]\ttrain-rmse:1.86744e+06\ttest-rmse:2.5646e+06\n",
      "[250]\ttrain-rmse:1.83353e+06\ttest-rmse:2.55781e+06\n",
      "[275]\ttrain-rmse:1.80126e+06\ttest-rmse:2.55367e+06\n",
      "[300]\ttrain-rmse:1.77318e+06\ttest-rmse:2.55144e+06\n",
      "[325]\ttrain-rmse:1.74344e+06\ttest-rmse:2.54833e+06\n",
      "[350]\ttrain-rmse:1.71692e+06\ttest-rmse:2.54686e+06\n",
      "[375]\ttrain-rmse:1.69138e+06\ttest-rmse:2.54489e+06\n",
      "[400]\ttrain-rmse:1.66638e+06\ttest-rmse:2.54342e+06\n",
      "[425]\ttrain-rmse:1.64369e+06\ttest-rmse:2.54194e+06\n",
      "[450]\ttrain-rmse:1.62069e+06\ttest-rmse:2.53915e+06\n",
      "[475]\ttrain-rmse:1.59906e+06\ttest-rmse:2.53767e+06\n",
      "[500]\ttrain-rmse:1.57762e+06\ttest-rmse:2.53793e+06\n",
      "best num_boost_rounds =  485\n"
     ]
    }
   ],
   "source": [
    "# read csv files\n",
    "df_train = pd.read_csv(wd+\"/train.csv\", parse_dates=['timestamp'])\n",
    "df_test = pd.read_csv(wd+\"test.csv\", parse_dates=['timestamp'])\n",
    "df_macro = pd.read_csv(wd+\"macro.csv\", parse_dates=['timestamp'])\n",
    "\n",
    "df_train.drop(df_train[df_train[\"life_sq\"] > 7000].index, inplace=True)\n",
    "\n",
    "mult = 0.969\n",
    "y_train = df_train['price_doc'].values * mult + 10\n",
    "id_test = df_test['id']\n",
    "id_train = df_train['id']\n",
    "\n",
    "df_train.drop(['id', 'price_doc'], axis=1, inplace=True)\n",
    "df_test.drop(['id'], axis=1, inplace=True)\n",
    "\n",
    "num_train = len(df_train)\n",
    "df_all = pd.concat([df_train, df_test])\n",
    "df_all = df_all.join(df_macro, on='timestamp', rsuffix='_macro')\n",
    "print(df_all.shape)\n",
    "\n",
    "# Add month-year\n",
    "month_year = (df_all.timestamp.dt.month + df_all.timestamp.dt.year * 100)\n",
    "month_year_cnt_map = month_year.value_counts().to_dict()\n",
    "df_all['month_year_cnt'] = month_year.map(month_year_cnt_map)\n",
    "\n",
    "# Add week-year count\n",
    "week_year = (df_all.timestamp.dt.weekofyear + df_all.timestamp.dt.year * 100)\n",
    "week_year_cnt_map = week_year.value_counts().to_dict()\n",
    "df_all['week_year_cnt'] = week_year.map(week_year_cnt_map)\n",
    "\n",
    "# Add month and day-of-week\n",
    "df_all['month'] = df_all.timestamp.dt.month\n",
    "df_all['dow'] = df_all.timestamp.dt.dayofweek\n",
    "\n",
    "# Other feature engineering\n",
    "df_all['rel_floor'] = df_all['floor'] / df_all['max_floor'].astype(float)\n",
    "df_all['rel_kitch_sq'] = df_all['kitch_sq'] / df_all['full_sq'].astype(float)\n",
    "\n",
    "train['building_name'] = pd.factorize(train.sub_area + train['metro_km_avto'].astype(str))[0]\n",
    "test['building_name'] = pd.factorize(test.sub_area + test['metro_km_avto'].astype(str))[0]\n",
    "\n",
    "def add_time_features(col):\n",
    "   col_month_year = pd.Series(pd.factorize(train[col].astype(str) + month_year.astype(str))[0])\n",
    "   train[col + '_month_year_cnt'] = col_month_year.map(col_month_year.value_counts())\n",
    "\n",
    "   col_week_year = pd.Series(pd.factorize(train[col].astype(str) + week_year.astype(str))[0])\n",
    "   train[col + '_week_year_cnt'] = col_week_year.map(col_week_year.value_counts())\n",
    "\n",
    "add_time_features('building_name')\n",
    "add_time_features('sub_area')\n",
    "\n",
    "def add_time_features(col):\n",
    "   col_month_year = pd.Series(pd.factorize(test[col].astype(str) + month_year.astype(str))[0])\n",
    "   test[col + '_month_year_cnt'] = col_month_year.map(col_month_year.value_counts())\n",
    "\n",
    "   col_week_year = pd.Series(pd.factorize(test[col].astype(str) + week_year.astype(str))[0])\n",
    "   test[col + '_week_year_cnt'] = col_week_year.map(col_week_year.value_counts())\n",
    "\n",
    "add_time_features('building_name')\n",
    "add_time_features('sub_area')\n",
    "\n",
    "# Drop timestamp column \n",
    "df_all.drop(['timestamp', 'timestamp_macro'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "factorize = lambda t: pd.factorize(t[1])[0]\n",
    "\n",
    "df_obj = df_all.select_dtypes(include=['object'])\n",
    "\n",
    "X_all = np.c_[\n",
    "    df_all.select_dtypes(exclude=['object']).values,\n",
    "    np.array(list(map(factorize, df_obj.iteritems()))).T\n",
    "]\n",
    "print(X_all.shape)\n",
    "\n",
    "X_train = X_all[:num_train]\n",
    "X_test = X_all[num_train:]\n",
    "\n",
    "\n",
    "# Deal with categorical values\n",
    "df_numeric = df_all.select_dtypes(exclude=['object'])\n",
    "df_obj = df_all.select_dtypes(include=['object']).copy()\n",
    "\n",
    "for c in df_obj:\n",
    "    df_obj[c] = pd.factorize(df_obj[c])[0]\n",
    "\n",
    "df_values = pd.concat([df_numeric, df_obj], axis=1)\n",
    "\n",
    "\n",
    "# Convert to numpy values\n",
    "X_all = df_values.values\n",
    "print(X_all.shape)\n",
    "\n",
    "X_train = X_all[:num_train]\n",
    "X_test = X_all[num_train:]\n",
    "\n",
    "df_columns = df_values.columns\n",
    "\n",
    "# Run XGB Model\n",
    "xgb_params = {\n",
    "    'eta': 0.05,\n",
    "    'max_depth': 5,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'rmse',\n",
    "    'silent': 1\n",
    "}\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, y_train, feature_names=df_columns)\n",
    "dtest = xgb.DMatrix(X_test, feature_names=df_columns)\n",
    "\n",
    "cv_output = xgb.cv(xgb_params, dtrain, num_boost_round=1000, early_stopping_rounds=20, verbose_eval=25, show_stdv=False)\n",
    "print('best num_boost_rounds = ', len(cv_output))\n",
    "num_boost_rounds = len(cv_output) #\n",
    "\n",
    "model03 = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round=num_boost_rounds)\n",
    "\n",
    "#y_pred = model3.predict(dtest)\n",
    "#df_sub = pd.DataFrame({'id': id_test, 'price_doc': y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ytrain_pred03 = model03.predict(dtrain)\n",
    "\n",
    "df_train03 = pd.DataFrame({'id': id_train, 'price_pred03': ytrain_pred03})\n",
    "\n",
    "df_train03.to_csv(wd+\"/stacking/model03_train.csv\", index=False)\n",
    "\n",
    "ytest_pred03 = model03.predict(dtest)\n",
    "\n",
    "df_test03 = pd.DataFrame({'id': id_test, 'price_pred03': ytest_pred03})\n",
    "\n",
    "df_test03.to_csv(wd+\"/stacking/model03_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Averaging 3 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "first_result = df_test01.merge(df_test03, on=\"id\")\n",
    "first_result[\"price_com1\"] = np.exp( .714*np.log(first_result.price_pred01) +\n",
    "                                    .286*np.log(first_result.price_pred03) )  \n",
    "result = first_result.merge(df_test02, on=\"id\")\n",
    "\n",
    "result[\"price_doc\"] = np.exp( .78*np.log(result.price_com1) +\n",
    "                              .22*np.log(result.price_pred02) )\n",
    "result[\"price_doc\"] =result[\"price_doc\"] *0.9925                              \n",
    "result.drop([\"price_pred01\",\"price_pred03\",\"price_com1\",\"price_pred02\"],axis=1,inplace=True)\n",
    "result.head()\n",
    "result.to_csv(wd+'Final_Submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Stacking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/pandas/core/indexing.py:141: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "macro_cols = ['balance_trade',  'average_provision_of_build_contract', \n",
    "              'micex_rgbi_tr', 'micex_cbi_tr', 'deposits_rate', 'mortgage_rate',\n",
    "              'income_per_cap', 'rent_price_4+room_bus', \n",
    "              'gdp_annual','deposits_rate', ]\n",
    "\n",
    "train_df = pd.read_csv(wd+'/train.csv')\n",
    "test_df = pd.read_csv(wd+'/test.csv')\n",
    "macro_df = pd.read_csv(wd+'/macro.csv',usecols=['timestamp'] + macro_cols)\n",
    "\n",
    "id_test = test_df.id\n",
    "id_all = pd.concat([train_df, test_df])['id']\n",
    "\n",
    "model01_train = pd.read_csv(wd+\"/stacking/model01_train.csv\")\n",
    "model01_train.columns = ['id', 'model01']\n",
    "model01_test = pd.read_csv(wd+\"/stacking/model01_test.csv\")\n",
    "model01_test.columns = ['id', 'model01']\n",
    "\n",
    "model02_train = pd.read_csv(wd+\"/stacking/model02_train.csv\")\n",
    "model02_train.columns = ['id', 'model02']\n",
    "model02_test = pd.read_csv(wd+\"/stacking/model02_test.csv\")\n",
    "model02_test.columns = ['id', 'model02']\n",
    "\n",
    "model03_train = pd.read_csv(wd+\"/stacking/model03_train.csv\")\n",
    "model03_train.columns = ['id', 'model03']\n",
    "model03_test = pd.read_csv(wd+\"/stacking/model03_test.csv\")\n",
    "model03_test.columns = ['id', 'model03']\n",
    "\n",
    "model02_train[\"model02\"].ix[model02_train[\"model02\"]<0] = -model02_train[\"model02\"]\n",
    "\n",
    "train_df = pd.merge(train_df, model01_train, on='id', how='left')\n",
    "train_df = pd.merge(train_df, model02_train, on='id', how='left')\n",
    "train_df = pd.merge(train_df, model03_train, on='id', how='left')\n",
    "\n",
    "test_df = pd.merge(test_df, model01_test, on='id', how='left')\n",
    "test_df = pd.merge(test_df, model02_test, on='id', how='left')\n",
    "test_df = pd.merge(test_df, model03_test, on='id', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/pandas/core/indexing.py:141: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30471, 309)\n",
      "(7662, 308)\n"
     ]
    }
   ],
   "source": [
    "# Impute the outlier of full_sq, life_sq, kitch_sq with NaN\n",
    "train_df['full_sq'].ix[train_df['full_sq'] > 2000]= np.nan\n",
    "train_df['life_sq'].ix[train_df['life_sq'] > 2000]= np.nan\n",
    "train_df['kitch_sq'].ix[train_df['kitch_sq'] > 500]= np.nan\n",
    "\n",
    "train_df['life_sq'].ix[train_df['life_sq'] >= train_df['full_sq']] = np.nan\n",
    "test_df['life_sq'].ix[test_df['life_sq'] >= test_df['full_sq']] = np.nan\n",
    "\n",
    "train_df['kitch_sq'].ix[train_df['kitch_sq'] >= train_df['full_sq']] = np.nan\n",
    "test_df['kitch_sq'].ix[test_df['kitch_sq'] >= test_df['full_sq']] = np.nan\n",
    "\n",
    "train_df['rel_life_sq'] = train_df['life_sq'] / train_df['full_sq'].astype(float)\n",
    "test_df['rel_life_sq'] = test_df['life_sq'] / test_df['full_sq'].astype(float)\n",
    "\n",
    "train_df['rel_floor'] = train_df['floor'] / train_df['max_floor'].astype(float)\n",
    "test_df['rel_floor'] = test_df['floor'] / test_df['max_floor'].astype(float)\n",
    "train_df['rel_floor'].ix[train_df['rel_floor'] == np.inf] = np.nan\n",
    "test_df['rel_floor'].ix[test_df['rel_floor'] == np.inf] = np.nan\n",
    "\n",
    "train_df['rel_kitch_sq'] = train_df['kitch_sq'] / train_df['full_sq'].astype(float)\n",
    "test_df['rel_kitch_sq'] = test_df['kitch_sq'] / test_df['full_sq'].astype(float)\n",
    "\n",
    "\n",
    "train_df[\"year_old\"] = 2020 - train_df[\"build_year\"]\n",
    "test_df[\"year_old\"] = 2020 - test_df[\"build_year\"]\n",
    "\n",
    "train_df[\"avg_sq\"] = train_df[\"full_sq\"]/train_df[\"num_room\"]\n",
    "test_df[\"avg_sq\"] = test_df[\"full_sq\"]/test_df[\"num_room\"]\n",
    "\n",
    "train_df.loc[train_df['state'] == 33, 'state'] = train_df['state'].mode().iloc[0]\n",
    "\n",
    "train_df.loc[train_df['build_year'] == 20052009, 'build_year'] = 2007\n",
    "train_df.loc[train_df['build_year'] <= 1691, 'build_year'] = np.nan\n",
    "test_df.loc[test_df['build_year'] <= 1691, 'build_year'] = np.nan\n",
    "\n",
    "# Merge macro columns\n",
    "train_df = pd.merge(train_df, macro_df, on='timestamp', how='left')\n",
    "test_df = pd.merge(test_df, macro_df, on='timestamp', how='left')\n",
    "                   \n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:8.1708e+06\ttest-rmse:8.173e+06\n",
      "[20]\ttrain-rmse:3.32572e+06\ttest-rmse:3.38638e+06\n",
      "[40]\ttrain-rmse:1.85856e+06\ttest-rmse:2.00995e+06\n",
      "[60]\ttrain-rmse:1.50199e+06\ttest-rmse:1.71944e+06\n",
      "[80]\ttrain-rmse:1.40988e+06\ttest-rmse:1.66652e+06\n",
      "[100]\ttrain-rmse:1.36816e+06\ttest-rmse:1.6549e+06\n",
      "[120]\ttrain-rmse:1.33983e+06\ttest-rmse:1.65157e+06\n",
      "[140]\ttrain-rmse:1.31375e+06\ttest-rmse:1.6511e+06\n",
      "[160]\ttrain-rmse:1.28698e+06\ttest-rmse:1.65e+06\n",
      "[180]\ttrain-rmse:1.25725e+06\ttest-rmse:1.65009e+06\n",
      "[200]\ttrain-rmse:1.22974e+06\ttest-rmse:1.649e+06\n",
      "[220]\ttrain-rmse:1.19982e+06\ttest-rmse:1.64837e+06\n",
      "[240]\ttrain-rmse:1.17476e+06\ttest-rmse:1.64828e+06\n",
      "[260]\ttrain-rmse:1.15156e+06\ttest-rmse:1.64867e+06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price_doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30474</td>\n",
       "      <td>5.152947e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30475</td>\n",
       "      <td>8.377446e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30476</td>\n",
       "      <td>5.110135e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30477</td>\n",
       "      <td>5.996344e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30478</td>\n",
       "      <td>4.649760e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30479</td>\n",
       "      <td>8.319586e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30480</td>\n",
       "      <td>4.110743e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30481</td>\n",
       "      <td>4.062334e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30482</td>\n",
       "      <td>4.513150e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>30483</td>\n",
       "      <td>4.441862e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>30484</td>\n",
       "      <td>5.659324e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>30485</td>\n",
       "      <td>4.680700e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>30486</td>\n",
       "      <td>3.277217e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>30487</td>\n",
       "      <td>3.584932e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>30488</td>\n",
       "      <td>6.098874e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>30489</td>\n",
       "      <td>6.198670e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>30490</td>\n",
       "      <td>2.480224e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>30491</td>\n",
       "      <td>1.625142e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>30492</td>\n",
       "      <td>5.861056e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>30493</td>\n",
       "      <td>1.004654e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>30494</td>\n",
       "      <td>6.762554e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>30495</td>\n",
       "      <td>1.032689e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>30496</td>\n",
       "      <td>7.150174e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>30497</td>\n",
       "      <td>8.490700e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>30498</td>\n",
       "      <td>4.351406e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>30499</td>\n",
       "      <td>6.981909e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>30500</td>\n",
       "      <td>1.191146e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>30501</td>\n",
       "      <td>6.918700e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>30502</td>\n",
       "      <td>3.048581e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30503</td>\n",
       "      <td>5.937178e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7632</th>\n",
       "      <td>38106</td>\n",
       "      <td>5.562498e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7633</th>\n",
       "      <td>38107</td>\n",
       "      <td>3.153264e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7634</th>\n",
       "      <td>38108</td>\n",
       "      <td>8.030810e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7635</th>\n",
       "      <td>38109</td>\n",
       "      <td>4.766223e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7636</th>\n",
       "      <td>38110</td>\n",
       "      <td>3.362550e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7637</th>\n",
       "      <td>38111</td>\n",
       "      <td>3.358911e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7638</th>\n",
       "      <td>38112</td>\n",
       "      <td>3.068561e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7639</th>\n",
       "      <td>38113</td>\n",
       "      <td>7.582884e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7640</th>\n",
       "      <td>38114</td>\n",
       "      <td>6.474851e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7641</th>\n",
       "      <td>38115</td>\n",
       "      <td>3.002945e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7642</th>\n",
       "      <td>38116</td>\n",
       "      <td>4.126057e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7643</th>\n",
       "      <td>38117</td>\n",
       "      <td>4.459643e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7644</th>\n",
       "      <td>38118</td>\n",
       "      <td>6.434910e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7645</th>\n",
       "      <td>38119</td>\n",
       "      <td>2.737203e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7646</th>\n",
       "      <td>38120</td>\n",
       "      <td>6.928856e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7647</th>\n",
       "      <td>38121</td>\n",
       "      <td>3.066566e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7648</th>\n",
       "      <td>38122</td>\n",
       "      <td>2.181924e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7649</th>\n",
       "      <td>38123</td>\n",
       "      <td>1.820649e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7650</th>\n",
       "      <td>38124</td>\n",
       "      <td>6.642848e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7651</th>\n",
       "      <td>38125</td>\n",
       "      <td>7.884093e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7652</th>\n",
       "      <td>38126</td>\n",
       "      <td>4.795938e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7653</th>\n",
       "      <td>38127</td>\n",
       "      <td>5.899449e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7654</th>\n",
       "      <td>38128</td>\n",
       "      <td>2.425463e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7655</th>\n",
       "      <td>38129</td>\n",
       "      <td>2.976528e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7656</th>\n",
       "      <td>38130</td>\n",
       "      <td>4.354880e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7657</th>\n",
       "      <td>38131</td>\n",
       "      <td>8.043590e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7658</th>\n",
       "      <td>38132</td>\n",
       "      <td>3.820944e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7659</th>\n",
       "      <td>38133</td>\n",
       "      <td>2.860674e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7660</th>\n",
       "      <td>38134</td>\n",
       "      <td>2.535223e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7661</th>\n",
       "      <td>38135</td>\n",
       "      <td>6.514830e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7662 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id     price_doc\n",
       "0     30474  5.152947e+06\n",
       "1     30475  8.377446e+06\n",
       "2     30476  5.110135e+06\n",
       "3     30477  5.996344e+06\n",
       "4     30478  4.649760e+06\n",
       "5     30479  8.319586e+06\n",
       "6     30480  4.110743e+06\n",
       "7     30481  4.062334e+06\n",
       "8     30482  4.513150e+06\n",
       "9     30483  4.441862e+06\n",
       "10    30484  5.659324e+06\n",
       "11    30485  4.680700e+06\n",
       "12    30486  3.277217e+06\n",
       "13    30487  3.584932e+06\n",
       "14    30488  6.098874e+06\n",
       "15    30489  6.198670e+06\n",
       "16    30490  2.480224e+07\n",
       "17    30491  1.625142e+07\n",
       "18    30492  5.861056e+06\n",
       "19    30493  1.004654e+07\n",
       "20    30494  6.762554e+06\n",
       "21    30495  1.032689e+07\n",
       "22    30496  7.150174e+06\n",
       "23    30497  8.490700e+06\n",
       "24    30498  4.351406e+06\n",
       "25    30499  6.981909e+06\n",
       "26    30500  1.191146e+07\n",
       "27    30501  6.918700e+06\n",
       "28    30502  3.048581e+06\n",
       "29    30503  5.937178e+06\n",
       "...     ...           ...\n",
       "7632  38106  5.562498e+06\n",
       "7633  38107  3.153264e+06\n",
       "7634  38108  8.030810e+06\n",
       "7635  38109  4.766223e+06\n",
       "7636  38110  3.362550e+06\n",
       "7637  38111  3.358911e+06\n",
       "7638  38112  3.068561e+06\n",
       "7639  38113  7.582884e+06\n",
       "7640  38114  6.474851e+06\n",
       "7641  38115  3.002945e+06\n",
       "7642  38116  4.126057e+06\n",
       "7643  38117  4.459643e+06\n",
       "7644  38118  6.434910e+06\n",
       "7645  38119  2.737203e+06\n",
       "7646  38120  6.928856e+06\n",
       "7647  38121  3.066566e+06\n",
       "7648  38122  2.181924e+06\n",
       "7649  38123  1.820649e+06\n",
       "7650  38124  6.642848e+06\n",
       "7651  38125  7.884093e+06\n",
       "7652  38126  4.795938e+06\n",
       "7653  38127  5.899449e+05\n",
       "7654  38128  2.425463e+06\n",
       "7655  38129  2.976528e+06\n",
       "7656  38130  4.354880e+06\n",
       "7657  38131  8.043590e+06\n",
       "7658  38132  3.820944e+06\n",
       "7659  38133  2.860674e+06\n",
       "7660  38134  2.535223e+06\n",
       "7661  38135  6.514830e+06\n",
       "\n",
       "[7662 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = train_df[\"price_doc\"]\n",
    "x_train = train_df.drop([\"id\", \"timestamp\", \"price_doc\"], axis=1)\n",
    "x_test = test_df.drop([\"id\", \"timestamp\"], axis=1)\n",
    "\n",
    "# Encode categorical variables\n",
    "for c in x_train.columns:\n",
    "    if x_train[c].dtype == 'object':\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(x_train[c].values.tolist()+x_test[c].values.tolist()) \n",
    "        x_train[c] = lbl.transform(list(x_train[c].values))\n",
    "        \n",
    "for c in x_test.columns:\n",
    "    if x_test[c].dtype == 'object':\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(x_train[c].values.tolist()+x_test[c].values.tolist())\n",
    "        x_test[c] = lbl.transform(list(x_test[c].values))\n",
    "\n",
    "xgb_params = {\n",
    "    'eta': 0.05,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 1,\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'rmse',\n",
    "    'silent': 1\n",
    "}\n",
    "\n",
    "df_all = pd.concat([x_train, x_test])\n",
    "dtrain = xgb.DMatrix(x_train, y_train)\n",
    "dtest = xgb.DMatrix(x_test)\n",
    "dall = xgb.DMatrix(df_all)\n",
    "\n",
    "cv_output = xgb.cv(xgb_params, dtrain, num_boost_round=1000, early_stopping_rounds=50, # 20\n",
    "    verbose_eval=20, show_stdv=False)\n",
    "cv_output[['train-rmse-mean', 'test-rmse-mean']].plot()\n",
    "\n",
    "num_boost_rounds = len(cv_output)\n",
    "model = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round= num_boost_rounds)\n",
    "\n",
    "y_predict = model.predict(dtest)\n",
    "output = pd.DataFrame({'id': id_test, 'price_doc': y_predict})\n",
    "\n",
    "#output.to_csv(wd+'/stacking.csv', index=False)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output['price_doc'] = output['price_doc'].abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output.to_csv(wd+'/stacking4.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Stacking did not improve the score in LeardBoard, So we use the weighted averaging result."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
